{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829ce11e-a687-443b-880e-6425f8c9ebd3",
   "metadata": {},
   "source": [
    "# ---------------------------------------\n",
    "# Step 1: Reading and Combining Data\n",
    "# ---------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7492f19-196f-403b-8c13-05e5d8c1acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a10e7ea9-2345-481b-ab03-1a9395288766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9 CSV files:\n",
      "- Bio-Diesel_PassengerVehicle_Stats.csv\n",
      "- Compressed Natural Gas_PassengerVehicle_Stats.csv\n",
      "- Diesel_PassengerVehicle_Stats.csv\n",
      "- Electric_PassengerVehicle_Stats.csv\n",
      "- Flex Fuel_PassengerVehicle_Stats.csv\n",
      "- Gasoline_PassengerVehicle_Stats.csv\n",
      "- Horse_PassengerVehicle_Stats.csv\n",
      "- Hybrid_PassengerVehicle_Stats.csv\n",
      "- Pedal_PassengerVehicle_Stats.csv\n",
      "\n",
      "Combined DataFrame shape: (16602, 17)\n",
      "Columns: ['Unnamed: 0', 'Public Vehicle Number', 'Status', 'Vehicle Make', 'Vehicle Model', 'Vehicle Model Year', 'Vehicle Color', 'Vehicle Fuel Source', 'Wheelchair Accessible', 'Company Name', 'Address', 'City', 'State', 'ZIP Code', 'Taxi Affiliation', 'Taxi Medallion License Management ', 'Record ID']\n"
     ]
    }
   ],
   "source": [
    "# Load all CSV files into a list of DataFrames\n",
    "try:\n",
    "    csv_files = glob.glob(data_path)\n",
    "    if len(csv_files) == 0:\n",
    "        print(\"Error: No CSV files found in data\\\\PassengerVehicle_Stats\")\n",
    "        raise FileNotFoundError(\"No CSV files found.\")\n",
    "    if len(csv_files) != 9:\n",
    "        print(f\"Warning: Expected 9 CSV files, found {len(csv_files)}\")\n",
    "    df_list = [pd.read_csv(file) for file in csv_files]\n",
    "    print(f\"Loaded {len(df_list)} CSV files:\")\n",
    "    for file in csv_files:\n",
    "        print(f\"- {os.path.basename(file)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV files: {e}\")\n",
    "    raise\n",
    "\n",
    "# Concatenate into a single DataFrame\n",
    "vehicles_df = pd.concat(df_list, ignore_index=True)\n",
    "print(\"\\nCombined DataFrame shape:\", vehicles_df.shape)\n",
    "print(\"Columns:\", vehicles_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e62b682-8f61-48b3-8563-b0993974e6ae",
   "metadata": {},
   "source": [
    "# ---------------------------------------\n",
    "# Step 2: Initial Data Exploration and Cleaning\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a26009f-825e-4b74-911d-2f6fdd3096fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary index column\n",
    "# Reason: 'Unnamed: 0' is likely an index from the CSV files, redundant for analysis.\n",
    "if 'Unnamed: 0' in vehicles_df.columns:\n",
    "    vehicles_df = vehicles_df.drop(columns=['Unnamed: 0'])\n",
    "    print(\"Dropped 'Unnamed: 0' column.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b175b44f-568f-4fe8-af8e-e4dee66b9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column with trailing space\n",
    "# Reason: Standardizes column name for consistency and ease of use.\n",
    "vehicles_df = vehicles_df.rename(columns={'Taxi Medallion License Management ': 'Taxi Medallion License Management'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19a6f762-b9ac-4d08-ac91-ca5e32ce46b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16576 entries, 0 to 16601\n",
      "Data columns (total 15 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Status                             16576 non-null  object \n",
      " 1   Vehicle Make                       16576 non-null  object \n",
      " 2   Vehicle Model                      16576 non-null  object \n",
      " 3   Vehicle Model Year                 16576 non-null  float64\n",
      " 4   Vehicle Color                      16576 non-null  object \n",
      " 5   Vehicle Fuel Source                16576 non-null  object \n",
      " 6   Wheelchair Accessible              16576 non-null  object \n",
      " 7   Company Name                       16576 non-null  object \n",
      " 8   City                               16576 non-null  object \n",
      " 9   State                              14790 non-null  object \n",
      " 10  ZIP Code                           16576 non-null  object \n",
      " 11  Taxi Affiliation                   16576 non-null  object \n",
      " 12  Taxi Medallion License Management  16576 non-null  object \n",
      " 13  Record ID                          16576 non-null  object \n",
      " 14  Vehicle Type                       16576 non-null  object \n",
      "dtypes: float64(1), object(14)\n",
      "memory usage: 2.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Examine DataFrame structure\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(vehicles_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb02bbdb-1869-4616-b29b-114e74a8da96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Null Values:\n",
      "Status                                  0\n",
      "Vehicle Make                            0\n",
      "Vehicle Model                           0\n",
      "Vehicle Model Year                      0\n",
      "Vehicle Color                           0\n",
      "Vehicle Fuel Source                     0\n",
      "Wheelchair Accessible                   0\n",
      "Company Name                            0\n",
      "City                                    0\n",
      "State                                1786\n",
      "ZIP Code                                0\n",
      "Taxi Affiliation                        0\n",
      "Taxi Medallion License Management       0\n",
      "Record ID                               0\n",
      "Vehicle Type                            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check initial null values\n",
    "print(\"\\nInitial Null Values:\")\n",
    "print(vehicles_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "966a2415-43e4-426e-9b06-0535c917f093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 932 duplicate rows. New shape: (15644, 15)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate records\n",
    "# Reason: Duplicates may result from data entry errors or merging issues, leading to\n",
    "# overcounting of vehicles. Removing them ensures each vehicle is represented once.\n",
    "initial_rows = vehicles_df.shape[0]\n",
    "vehicles_df = vehicles_df.drop_duplicates()\n",
    "print(f\"\\nRemoved {initial_rows - vehicles_df.shape[0]} duplicate rows. New shape:\", vehicles_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c41cdd1-17a9-425b-8c61-b692d9b8e7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rows with any null values: 1694\n",
      "\n",
      "Columns before null check: ['Status', 'Vehicle Make', 'Vehicle Model', 'Vehicle Model Year', 'Vehicle Color', 'Vehicle Fuel Source', 'Wheelchair Accessible', 'Company Name', 'City', 'State', 'ZIP Code', 'Taxi Affiliation', 'Taxi Medallion License Management', 'Record ID', 'Vehicle Type']\n",
      "No rows with nulls in critical columns. Retaining all rows for imputation.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate null records\n",
    "# Reason: Nulls are removed only if critical columns (`Public Vehicle Number`, `Record ID`)\n",
    "# are missing, as these are unique identifiers. Other nulls are retained for imputation.\n",
    "print(f\"\\nNumber of rows with any null values: {len(vehicles_df[vehicles_df.isnull().any(axis=1)])}\")\n",
    "print(\"\\nColumns before null check:\", vehicles_df.columns.tolist())\n",
    "critical_columns = [col for col in ['Public Vehicle Number', 'Record ID'] if col in vehicles_df.columns]\n",
    "if not critical_columns:\n",
    "    print(\"No critical columns ('Public Vehicle Number', 'Record ID') found. Skipping null check.\")\n",
    "else:\n",
    "    null_critical = vehicles_df[critical_columns].isnull().any(axis=1)\n",
    "    if null_critical.sum() > 0:\n",
    "        print(f\"Found {null_critical.sum()} rows with nulls in critical columns: {critical_columns}\")\n",
    "        vehicles_df = vehicles_df[~null_critical]\n",
    "        print(\"Removed rows with nulls in critical columns. New shape:\", vehicles_df.shape)\n",
    "    else:\n",
    "        print(\"No rows with nulls in critical columns. Retaining all rows for imputation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88370066-c591-4b58-bb82-b9b6ad206e91",
   "metadata": {},
   "source": [
    "\n",
    "# ---------------------------------------\n",
    "# Step 3: Handle Outliers and Missing Values\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf474568-3cfa-4fe3-b0cb-ab908abd6862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outlier Detection for Vehicle Model Year:\n",
      "Outliers in Vehicle Model Year:\n",
      "102      2001.0\n",
      "104      2002.0\n",
      "106      2000.0\n",
      "107      1993.0\n",
      "109      2000.0\n",
      "          ...  \n",
      "10400    1995.0\n",
      "10401    1991.0\n",
      "12496    2000.0\n",
      "13320    2000.0\n",
      "16588    1985.0\n",
      "Name: Vehicle Model Year, Length: 249, dtype: float64\n",
      "\n",
      "No invalid Vehicle Model Years detected.\n",
      "No missing Vehicle Model Years or column not found.\n",
      "\n",
      "Null Values After Imputation:\n",
      "Status                               0\n",
      "Vehicle Make                         0\n",
      "Vehicle Model                        0\n",
      "Vehicle Model Year                   0\n",
      "Vehicle Color                        0\n",
      "Vehicle Fuel Source                  0\n",
      "Wheelchair Accessible                0\n",
      "Company Name                         0\n",
      "City                                 0\n",
      "State                                0\n",
      "ZIP Code                             0\n",
      "Taxi Affiliation                     0\n",
      "Taxi Medallion License Management    0\n",
      "Record ID                            0\n",
      "Vehicle Type                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Outlier detection for Vehicle Model Year\n",
    "def detect_outliers(df, column):\n",
    "    \"\"\"\n",
    "    Detect outliers using the IQR method.\n",
    "    Returns indices and values of outliers for inspection.\n",
    "    \"\"\"\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)][column]\n",
    "    return outliers\n",
    "\n",
    "# Check outliers for Vehicle Model Year\n",
    "print(\"\\nOutlier Detection for Vehicle Model Year:\")\n",
    "if 'Vehicle Model Year' in vehicles_df.columns:\n",
    "    # Ensure Vehicle Model Year is numeric\n",
    "    vehicles_df['Vehicle Model Year'] = pd.to_numeric(vehicles_df['Vehicle Model Year'], errors='coerce')\n",
    "    outliers = detect_outliers(vehicles_df, 'Vehicle Model Year')\n",
    "    print(f\"Outliers in Vehicle Model Year:\\n{outliers}\\n\")\n",
    "    \n",
    "    # Handle invalid years\n",
    "    # Reason: Years <1900 or >2026 are invalid. Retain older but plausible years (e.g., 1980s).\n",
    "    current_year = 2025\n",
    "    invalid_years = vehicles_df[\n",
    "        (vehicles_df['Vehicle Model Year'] < 1900) | \n",
    "        (vehicles_df['Vehicle Model Year'] > current_year + 1)\n",
    "    ]\n",
    "    if not invalid_years.empty:\n",
    "        print(\"Invalid Vehicle Model Years detected:\\n\", invalid_years[['Vehicle Model Year']])\n",
    "        vehicles_df = vehicles_df[\n",
    "            (vehicles_df['Vehicle Model Year'] >= 1900) & \n",
    "            (vehicles_df['Vehicle Model Year'] <= current_year + 1) | \n",
    "            vehicles_df['Vehicle Model Year'].isnull()\n",
    "        ]\n",
    "        print(\"Removed invalid years. New shape:\", vehicles_df.shape)\n",
    "    else:\n",
    "        print(\"No invalid Vehicle Model Years detected.\")\n",
    "else:\n",
    "    print(\"Vehicle Model Year column not found. Skipping outlier detection.\")\n",
    "\n",
    "# Impute missing values\n",
    "# Reason: Imputation preserves data for analysis.\n",
    "# - Categorical: 'Unknown' avoids bias.\n",
    "# - Binary: 'No' for conservative imputation.\n",
    "# - Taxi-related: 'None' for non-taxi vehicles.\n",
    "# - Numerical: Median for robustness.\n",
    "columns_to_impute = {\n",
    "    'Status': 'Unknown',\n",
    "    'Vehicle Make': 'Unknown',\n",
    "    'Vehicle Model': 'Unknown',\n",
    "    'Vehicle Color': 'Unknown',\n",
    "    'Vehicle Fuel Source': 'Unknown',\n",
    "    'Wheelchair Accessible': 'No',\n",
    "    'Company Name': 'Unknown',\n",
    "    'City': 'Unknown',\n",
    "    'State': 'Unknown',\n",
    "    'ZIP Code': 'Unknown',\n",
    "    'Taxi Affiliation': 'None',\n",
    "    'Taxi Medallion License Management': 'None'\n",
    "}\n",
    "for col, value in columns_to_impute.items():\n",
    "    if col in vehicles_df.columns:\n",
    "        vehicles_df[col] = vehicles_df[col].fillna(value)\n",
    "\n",
    "# Impute Vehicle Model Year\n",
    "if 'Vehicle Model Year' in vehicles_df.columns and vehicles_df['Vehicle Model Year'].isnull().sum() > 0:\n",
    "    median_year = vehicles_df['Vehicle Model Year'].median()\n",
    "    vehicles_df['Vehicle Model Year'] = vehicles_df['Vehicle Model Year'].fillna(median_year)\n",
    "    print(f\"Imputed {vehicles_df['Vehicle Model Year'].isnull().sum()} missing Vehicle Model Years with median: {median_year}\")\n",
    "else:\n",
    "    print(\"No missing Vehicle Model Years or column not found.\")\n",
    "\n",
    "# Verify null values after imputation\n",
    "print(\"\\nNull Values After Imputation:\")\n",
    "print(vehicles_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f0e48e-ac80-47e2-a858-e4856aa56063",
   "metadata": {},
   "source": [
    "# ---------------------------------------\n",
    "# Step 4: Adding New Column (Vehicle Type)\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d703c4e-439b-4f10-afa6-4829407734a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Record ID values:\n",
      "0     12009Charter Sightseeing\n",
      "1     12248Charter Sightseeing\n",
      "2     13527Charter Sightseeing\n",
      "4     13528Charter Sightseeing\n",
      "5     12025Charter Sightseeing\n",
      "6     13513Charter Sightseeing\n",
      "7     13830Charter Sightseeing\n",
      "8     12026Charter Sightseeing\n",
      "9                      256Taxi\n",
      "10                    1616Taxi\n",
      "Name: Record ID, dtype: object\n",
      "\n",
      "Unique Record ID patterns:\n",
      "Record ID\n",
      "117Pedicab                  1\n",
      "12009Charter Sightseeing    1\n",
      "12248Charter Sightseeing    1\n",
      "13527Charter Sightseeing    1\n",
      "13528Charter Sightseeing    1\n",
      "12025Charter Sightseeing    1\n",
      "13513Charter Sightseeing    1\n",
      "13830Charter Sightseeing    1\n",
      "12026Charter Sightseeing    1\n",
      "256Taxi                     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "All unique Record ID suffixes:\n",
      "0\n",
      "Taxi                    6999\n",
      "Livery                  6001\n",
      "Charter Sightseeing      976\n",
      "Ambulance                781\n",
      "Medicar                  616\n",
      "Pedicab                  180\n",
      "Horse Drawn Carriage      56\n",
      "Jitney                    29\n",
      "Low Speed Electric         6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unmatched Record ID values (resulting in nan Vehicle Type):\n",
      "Series([], Name: Record ID, dtype: object)\n",
      "\n",
      "Unique Vehicle Types: ['Charter Sightseeing' 'Taxi' 'Medicar' 'Livery' 'Ambulance'\n",
      " 'Low Speed Electric' 'Pedicab' 'Jitney' 'Horse Drawn Carriage']\n",
      "\n",
      "Sample of Vehicle Type column:\n",
      "                  Record ID         Vehicle Type\n",
      "0  12009Charter Sightseeing  Charter Sightseeing\n",
      "1  12248Charter Sightseeing  Charter Sightseeing\n",
      "2  13527Charter Sightseeing  Charter Sightseeing\n",
      "4  13528Charter Sightseeing  Charter Sightseeing\n",
      "5  12025Charter Sightseeing  Charter Sightseeing\n"
     ]
    }
   ],
   "source": [
    "# Debug Record ID format\n",
    "if 'Record ID' in vehicles_df.columns:\n",
    "    print(\"\\nSample Record ID values:\")\n",
    "    print(vehicles_df['Record ID'].head(10))\n",
    "    print(\"\\nUnique Record ID patterns:\")\n",
    "    print(vehicles_df['Record ID'].str.split('_', n=1).str[0].value_counts().head(10))\n",
    "    \n",
    "    # Inspect all unique Record ID suffixes\n",
    "    print(\"\\nAll unique Record ID suffixes:\")\n",
    "    suffixes = vehicles_df['Record ID'].str.extract(r'(\\D+)$')[0].value_counts()\n",
    "    print(suffixes)\n",
    "    \n",
    "    # Extract Vehicle Type using regex\n",
    "    # Updated to include all known types\n",
    "    vehicles_df['Vehicle Type'] = vehicles_df['Record ID'].str.extract(\n",
    "        r'(Taxi|Pedicab|Bus|Charter\\sSightseeing|Livery|Ambulance|Shuttle|Jitney|Medicar|Low\\sSpeed\\sElectric|Horse\\sDrawn\\sCarriage)'\n",
    "    )\n",
    "    print(\"\\nUnmatched Record ID values (resulting in nan Vehicle Type):\")\n",
    "    print(vehicles_df[vehicles_df['Vehicle Type'].isna()]['Record ID'].head(10))\n",
    "    \n",
    "    # Impute nan with 'Unknown'\n",
    "    vehicles_df['Vehicle Type'] = vehicles_df['Vehicle Type'].fillna('Unknown')\n",
    "    print(\"\\nUnique Vehicle Types:\", vehicles_df['Vehicle Type'].unique())\n",
    "    print(\"\\nSample of Vehicle Type column:\")\n",
    "    print(vehicles_df[['Record ID', 'Vehicle Type']].head())\n",
    "else:\n",
    "    print(\"Record ID column not found. Skipping Vehicle Type creation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a95221-0c55-45a5-b8f1-407548b6425d",
   "metadata": {},
   "source": [
    "# ---------------------------------------\n",
    "# Step 5: Column Removal\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed8b8fc2-59d7-4780-bf56-0cd7ec81fd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns after removal: ['Status', 'Vehicle Make', 'Vehicle Model', 'Vehicle Model Year', 'Vehicle Color', 'Vehicle Fuel Source', 'Wheelchair Accessible', 'Company Name', 'City', 'State', 'ZIP Code', 'Taxi Affiliation', 'Taxi Medallion License Management', 'Record ID', 'Vehicle Type']\n"
     ]
    }
   ],
   "source": [
    "# Drop specified columns\n",
    "columns_to_drop = ['Address', 'Public Vehicle Number']\n",
    "vehicles_df = vehicles_df.drop(columns=[col for col in columns_to_drop if col in vehicles_df.columns])\n",
    "print(\"\\nColumns after removal:\", vehicles_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c37ebfd6-f007-45a1-bda0-cdd55d860d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed DataFrame saved to data\\processed_vehicles_task02.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the processed DataFrame\n",
    "output_path = 'data\\\\processed_vehicles_task02.csv'\n",
    "vehicles_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nProcessed DataFrame saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d67b3f6-227f-4f01-ad42-6bf2781d0528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Null Values:\n",
      "Status                               0\n",
      "Vehicle Make                         0\n",
      "Vehicle Model                        0\n",
      "Vehicle Model Year                   0\n",
      "Vehicle Color                        0\n",
      "Vehicle Fuel Source                  0\n",
      "Wheelchair Accessible                0\n",
      "Company Name                         0\n",
      "City                                 0\n",
      "State                                0\n",
      "ZIP Code                             0\n",
      "Taxi Affiliation                     0\n",
      "Taxi Medallion License Management    0\n",
      "Record ID                            0\n",
      "Vehicle Type                         0\n",
      "dtype: int64\n",
      "\n",
      "Vehicle Model Year Summary:\n",
      "count    15644.000000\n",
      "mean      2016.152582\n",
      "std          5.177405\n",
      "min       1980.000000\n",
      "25%       2013.000000\n",
      "50%       2016.000000\n",
      "75%       2020.000000\n",
      "max       2025.000000\n",
      "Name: Vehicle Model Year, dtype: float64\n",
      "\n",
      "Vehicle Type Distribution:\n",
      "Vehicle Type\n",
      "Taxi                    6999\n",
      "Livery                  6001\n",
      "Charter Sightseeing      976\n",
      "Ambulance                781\n",
      "Medicar                  616\n",
      "Pedicab                  180\n",
      "Horse Drawn Carriage      56\n",
      "Jitney                    29\n",
      "Low Speed Electric         6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check final null values\n",
    "print(\"\\nFinal Null Values:\")\n",
    "print(vehicles_df.isnull().sum())\n",
    "\n",
    "# Check data ranges for Vehicle Model Year\n",
    "if 'Vehicle Model Year' in vehicles_df.columns:\n",
    "    print(\"\\nVehicle Model Year Summary:\")\n",
    "    print(vehicles_df['Vehicle Model Year'].describe())\n",
    "\n",
    "# Check Vehicle Type distribution\n",
    "if 'Vehicle Type' in vehicles_df.columns:\n",
    "    print(\"\\nVehicle Type Distribution:\")\n",
    "    print(vehicles_df['Vehicle Type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f7493-a636-4ebf-8a44-19a9756d3822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
